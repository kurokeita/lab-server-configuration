name: "lab-services"

services:
  ###### Uptime Kuma #########
  kuma:
    image: louislam/uptime-kuma:1
    container_name: lab.uptime_kuma
    restart: unless-stopped
    volumes:
      - ./data/uptime_kuma:/app/data
    networks:
      - lab

  ###### Keycloak #########
  keycloak:
    container_name: lab.keycloak
    image: quay.io/keycloak/keycloak:latest
    ports:
      - "8080:8080"
    environment:
      KEYCLOAK_ADMIN: ${KC_ADMIN}
      KEYCLOAK_ADMIN_PASSWORD: ${KC_ADMIN_PASSWORD}
      # KC_PROXY: edge
      KC_HTTP_ENABLED: true
      KC_DB: postgres
      KC_DB_USERNAME: ${KC_DB_USERNAME}
      KC_DB_PASSWORD: ${KC_DB_PASSWORD}
      KC_DB_URL_HOST: ${KC_DB_HOST}
      KC_DB_URL_PORT: ${KC_DB_PORT}
      KC_HOSTNAME: keycloak.kurokeita.dev
      KC_HEALTH_ENABLED: true
      KC_PROXY_HEADERS: xforwarded
      KC_DB_URL: jdbc:postgresql://${KC_DB_HOST}:${KC_DB_PORT}/${KC_DB_NAME}?prepareThreshold=0
      # Connection pool settings for Supabase
      KC_DB_POOL_INITIAL_SIZE: 5
      KC_DB_POOL_MIN_SIZE: 5
      KC_DB_POOL_MAX_SIZE: 10
      KC_TRANSACTION_XA_ENABLED: false
    volumes:
      - ./data/keycloak:/opt/keycloak/data/
      - ./healthcheck/keycloak.sh:/opt/healthcheck.sh
    entrypoint: /bin/sh
    command: -c "/opt/keycloak/bin/kc.sh build && /opt/keycloak/bin/kc.sh start --optimized"
    user: root
    networks:
      - lab

  ###### CloudFlare Tunnel #########
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: lab.tunnel
    restart: always
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}
    networks:
      - lab

  ###### ddclient for Dynamic DNS #########
  ddclient:
    image: lscr.io/linuxserver/ddclient:latest
    container_name: lab.ddclient
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=Etc/UTC
    volumes:
      - ./data/ddclient:/config
    restart: always
    networks:
      - lab

  ###### Redis #########
  redis:
    container_name: lab.redis
    image: docker.io/library/redis:7
    restart: unless-stopped
    volumes:
      - ./data/redis:/data
    networks:
      - lab

  ###### Paperless #########
  paperless:
    container_name: lab.paperless
    image: ghcr.io/paperless-ngx/paperless-ngx:latest
    restart: unless-stopped
    depends_on:
      mariadb:
        condition: service_healthy
      redis:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000"]
      interval: 30s
      timeout: 10s
      retries: 5
    volumes:
      - ./data/paperless/data:/usr/src/paperless/data
      - ./data/paperless/media:/usr/src/paperless/media
      - ./data/paperless/export:/usr/src/paperless/export
      - ./data/paperless/consume:/usr/src/paperless/consume
    environment:
      PAPERLESS_REDIS: redis://redis:6379
      PAPERLESS_DBENGINE: mariadb
      PAPERLESS_DBHOST: ${PAPERLESS_DB_HOST}
      PAPERLESS_DBUSER: ${PAPERLESS_DB_USERNAME}
      PAPERLESS_DBPASS: ${PAPERLESS_DB_PASSWORD}
      PAPERLESS_DBPORT: ${PAPERLESS_DB_PORT}
      PAPERLESS_CSRF_TRUSTED_ORIGINS: ${PAPERLESS_URL}
    networks:
      - lab
    profiles:
      - paperless

  ###### Adguard #########
  adguard:
    image: adguard/adguardhome:latest
    container_name: lab.adguard
    environment:
      TZ: Etc/UTC
    depends_on:
      tailscale-adguard:
        condition: service_healthy
    volumes:
      - ./data/adguard/workdir:/opt/adguardhome/work
      - ./data/adguard/conf:/opt/adguardhome/conf
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "pgrep", "-f", "adguardhome"]
      interval: 1m
      timeout: 10s
      retries: 3
      start_period: 30s
    profiles:
      - vpn
    network_mode: service:tailscale-adguard

  ###### Tailscale for Adguard Home #########
  tailscale-adguard:
    image: tailscale/tailscale:latest
    container_name: lab.tailscale-adguard
    hostname: ${ADGUARD_HOSTNAME:-adguard}
    ports:
      - 3000:3000
    environment:
      TS_AUTHKEY: ${TS_AUTHKEY}
      TS_STATE_DIR: /var/lib/tailscale
      TS_USERSPACE: false
      TS_ENABLE_HEALTH_CHECK: true
      TS_LOCAL_ADDR_PORT: 127.0.0.1:9002
      TS_SERVE_CONFIG: /etc/tailscale/serve.json
      TS_EXTRA_ARGS: --accept-dns=true
    volumes:
      - ./data/tailscale-adguard/state:/var/lib/tailscale
      - ./configs/tailscale/adguard/serve.json:/etc/tailscale/serve.json:ro
    devices:
      - /dev/net/tun:/dev/net/tun
    cap_add:
      - net_admin
      - sys_module
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://127.0.0.1:9002/healthz"]
    restart: unless-stopped
    profiles:
      - vpn

networks:
  lab:
    driver: bridge
